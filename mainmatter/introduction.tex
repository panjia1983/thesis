\chapter{Introduction}
\label{chp:intro}
Intelligent robots are becoming increasing important in both industry and everyday life. In industry, the rising labor costs are motivating the manufacturers to consider using more robots in factories. For example, the supply of manufacturing robots has increased by 51 percent in China~\cite{IFR:report}, while the average minimum wage has increased by more than 20 percent in 2012. Similar trends are also occurring in Europe and USA: various types of smart robots are designed in order to make workers more productive and the manufacturers more competitive in terms of price and quality. Among these intelligent robots is the new ``Baxter'' robot~\cite{Brooks:2012:Baxter}, which is equipped with improved software that can help the robot learn various tasks, recognize different objects, and react intelligently to external forces. In everyday life, intelligent robots are expected to help or assist people. Such robots are expected to perform various tasks in the future, including 1) household and care support, such as cooking and laundry; 2) healthy life support, including chatting with the elderly and taking care of people with disabilities~\cite{Yamazaki:2012}. There are already several successful prototypes for assistant robots recently. For example, the PR2 robot from Willow Garage$^\copyright$ has been shown to be helpful for people with severe physical disabilities such as quadriplegia~\cite{PR2HumanityWeb}; humanoid robots such as the HPR-4 can perform human-like actions and can communicate with people using speeches~\cite{HRP-Cyber}. Besides their applications in industry and everyday life, modern intelligent robots can be helpful in other areas, including autonomous vehicles~\cite{Montemerlo:2008:JSE}, medical and surgical intervention ~\cite{Bonfe:2012}, emergency and disaster rescue~\cite{Fukushima:2011}, and military tasks~\cite{AlphaDog:2012}.



\begin{figure}[htb]
  \centering
  \includegraphics[width=\linewidth]{figs/1/pipeline-crop.pdf}
  \caption[Important hardware and software subsystems in a robot system]{Important hardware and software subsystems in a robot system. 1) Feed-forward system (box F), including task planning, navigation strategy, motion planning and trajectory generation. 2) Control system (box C), including kinematics, dynamics and control algorithms. 3) Actuator system (box A), including motors, servos, transmissions, etc. 4) Sensor system (box S), including various sensors such as camera, laser, IMU and the related low level sensor data processing algorithms such as signal processing, estimation and fusion. 5) Sensor post-processing system (Box S$^+$), including localization, mapping, etc. The main software component of a robot system is the \emph{high level planning and navigation}, which determines the instructions sent to the actuator system, given the desired tasks to be executed. \emph{Motion planning} is one important component of the high level planning and navigation, which focuses on computing the trajectory from the environment description.}
  \label{fig:1:pipeline}
\end{figure}

The tremendous improvement in the design and availability of intelligent robots over the last decade is based on progress in many related areas, including computer vision, artificial intelligence, machine learning, control, sensor systems, and mechanical systems, which correspond to different components of an intelligent robot system, as shown in Figure~\ref{fig:1:pipeline}. For example, SLAM (simultaneous localization and mapping) algorithm enables a robot to accurately track its position in an unknown environment~\cite{PR:2005}; with the help of advanced vision techniques, robots can now recognize and segment objects to be manipulated from the background point clouds~\cite{Rusu:2009:IROS}. Compared to traditional industrial robots, one important feature of the modern intelligent robot system is \emph{high level planning and navigation}. Its main task is to compute the low-level instructions provided to the robot actuator system, based on the high level descriptions for the tasks to be executed. This component is composed of many different sub-components as shown in Figure~\ref{fig:1:pipeline} and there is extensive work in this area, such as task planning~\cite{LPT:TPP:1989}, feedback from observation~\cite{KLP:2012:UPE,KLP:2011:NOW}, optimal control~\cite{Stengel:1994:OC}, and adaptive control~\cite{Astrom:1994:AC}, etc.


One of the most important sub-systems of the high level planning and navigation component is the \emph{motion planning} system, which enables the robot to move safely from an initial position to a goal position without colliding with any static or moving obstacles in the environment. Motion planning is critical for robots so that they can work efficiently and reliably in dynamic environments along with humans. Motion planning problems can be directly formalized and solved in the 3D workspace, e.g., the widely used potential field algorithms~\cite{Khatib:IJRR:1986}. However, these workspace solutions cannot easily handle robots with different geometries and mechanical constraints. To overcome these difficulties, 
motion planning is formalized and solved in a new space called the \emph{configuration space}~\cite{Lozano-Perez:1979:APC,LPT:APM:1981,LPT:SpatialPlanning:1983}. In configuration space, a robot with a complex geometric shape in 3D workspace is mapped to a point robot and its trajectory will correspond to a continuous curve in the high-dimensional configuration space (see Figure~\ref{fig:1:planning}). Based on the configuration space formulation, the motion planning problem can be solved in two steps:
\framebox{
\parbox{0.9\linewidth}{
\begin{enumerate}
\item Construct a representation of the configuration space.
\item Perform optimization computation based on the computed representation.
\end{enumerate}}}

Such configuration space based pipeline for motion planning is very successful and is adopted by many practical motion planning algorithms that find an optimal plan. Many different representations for the configuration space have been proposed, including polyhedron~\cite{Chazelle:ADS:1987}, semi-algebraic set~\cite{Canny:1988:AGC,Canny:1988:CKP}, graph~\cite{Kavraki96} or tree/forest~\cite{Kuffner00}. Different optimization operations have been designed for different applications, including computing a shortest path, computing the minimum distance to the boundary of a closed set inside the configuration space, etc. Moreover, the same pipeline is also implicitly used in some motion planning algorithms only computing a feasible path (i.e., the path is collision-free and does not violate other constraints). For example, many variants of Rapidly Exploring Random Tree (RRT)~\cite{Kuffner00} use various heuristics to guide the search toward the goal configuration while growing a search tree structure as an approximate representation of the configuration space. Such a strategy can be viewed as a variant of the above pipeline: the configuration space construction alternates with the optimization computation.


However, this $\Cspace$-based pipeline still has many challenges:
\begin{enumerate}
\item It is difficult to efficiently compute an approximate or exact representation of the configuration space, especially for high-DOF robots with high-dimensional configuration space, due to its exponential complexity (see Section~\ref{sec:1:configconstruction}).
\item The optimization in the computed representation for the configuration space can be time consuming, while many robotics applications require real-time planning in order to work reliably and efficiently in human environments with moving obstacles (see Section~\ref{sec:1:optimization}).
\item A robot in the real world depends on various sensors to acquire knowledge about its own state and the surrounding environments. As the sensors only provide noisy data, one important open problem is how to enhance the configuration space to consider robots and environments with noisy geometries, because previous work on configuration space based computations assume an exact representation of the robot and obstacles (see Section~\ref{sec:1:uncertainty}).
\end{enumerate}



\section{Configuration Space}
\label{sec:1:configurationSpace}
Configuration space is a key concept used in classical mechanics to describe and analyze the motion of many important systems~\cite{Arnold:1989}. Generally speaking, a \emph{configuration} $\q$ is a vector of independent parameters uniquely specifying the state of a system; and a configuration space or $\Cspace$ is a collection of all possible configurations for a given system. For example, for a system of point particles, the configuration is a vector describing the positions of all the particles and the corresponding $\Cspace$ is $\Rn$; a 3D rigid body has the configuration in terms of its position and orientation, and the configuration space is $\SEcubic$; if a 3D rigid body can only perform translation motion, then its configuration space reduces to $\Rcubic$; for an articulated object, its configuration is the vector of all the joint angles.

The configuration space of a robot $A$ is composed of two components: \emph{collision-free space} $\Cfree = \{\q: A(\q) \cap B = \emptyset\}$ and \emph{in-collision space} or \emph{obstacle space} $\Cobs = \{\q: A(\q) \cap B \neq \emptyset\}$, where $B$ is the geometry for obstacles in the environment and $A(\q)$ corresponds to $A$ located at the configuration $\q$. $\Cobs$ is a closed set and its boundary is denoted as the \emph{contact space} $\Ccont = \partial \Cobs$, which corresponds to the set of configurations where $A$ and $B$ just touch each other without penetration. Figure~\ref{fig:1:contactspace} shows an example of the $\Cspace$ of two objects where $\Ccont$ is highlighted with orange curves.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.6\linewidth]{figs/1/Ccont.pdf}
  \caption[The configuration space of two objects]{The configuration space of two objects. The orange curve highlights the contact space $\Ccont$ of A and B. A point inside/on the orange curve belongs to
  $\Cobs$ and a point outside the orange curve belongs to $\Cfree$.
  The red and green points will be used to denote configurations in $\Cobs$ and $\Cfree$, respectively. Intuitively, $\Ccont$ is the boundary that separates in-collision and collision-free configurations.}
  \label{fig:1:contactspace}
\end{figure}

In the special case when $A$ and $B$ are both rigid objects and robot $A$ can only perform translation motion, $\Cobs$ is equivalent to the well-known Minkowski sum between $A$ and $B$: $\Cobs = A \oplus (-B) = \{\x = \x_A + \x_B | \x_A \in A, \x_B \in -B \}$. One example of Minkowski sum is the $\Cobs$ in Figure~\ref{fig:1:contactspace}. When robot $A$ can perform both general motion (i.e., both translation and rotation), the geometry $\Cobs$ is much more complicated, as shown by the 2D example in Figure~\ref{fig:1:cspaceSE2}.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.9\linewidth]{figs/1/cspaceSE2.png}
  \caption[$\Cobs$ between 2D rigid objects $A$ and $B$]{$\Cobs$ between 2D rigid objects $A$ and $B$. For each rotation angle $\theta \in [0, 2\pi)$, we can compute the Minkowski sum between $A(\theta)$ and $-B$, where $A(\theta)$ is the resulting shape after rotating $A$ about origin with $\theta$ degrees. When stacking the Minkowski sums for all angles $\theta$, we obtain the $\Cobs$ between $A$ and $B$. This figure is modified from an online image.}
  \label{fig:1:cspaceSE2}
\end{figure}

Based on the notion of configuration space, the motion planning problem in 3D workspace can be reduced to path planning for a point robot in $\Cspace$, i.e., finding a curve in $\Cfree$ connecting the given initial and goal configurations of the robot.



\section{Configuration Space Construction}
\label{sec:1:configconstruction}
Before performing the motion planning computation in the configuration space, one prerequisite is to compute one representation for the configuration space $\Cspace$. As $\Cspace = \Cfree \cup \Cobs$ and $\Cfree \cap \Cobs = \emptyset$, we only need to construct the representation for either $\Cfree$ or $\Cobs$. Another equivalent solution is to compute $\Ccont$, the boundary between $\Cfree$ and $\Cobs$.

Previous work on configuration space construction can be categorized into two different methods: geometry-based or topology-based. Geometry-based methods compute the exact geometry representation of the configuration space while topology-based methods capture the connectivity of the configuration space.

Geometry-based methods are usually limited to low-dimensional configuration space, due to the combinatorial complexity when computing the boundary $\Cobs$ for high-dimensional configuration spaces. Most previous work focused on the special case when objects $A$ and $B$ are rigid bodies only performing translation motion. As mentioned in Section~\ref{sec:1:configurationSpace}, the resulting $\Cobs$ is the Minkowski sum between $A$ and $-B$. Even for this special case, the computational complexity to compute $\Cobs$ is still high: the complexity is $\mathcal O(mn)$ when $A$ and $B$ are both convex-objects and is $\mathcal O(m^3n^3)$ when $A$ and $B$ are both non-convex objects~\cite{Halperin:2002:RGC}, where $m$ and $n$ are the number of triangles in $A$ and $B$, respectively Beside the high complexity, most existing implementations for Minkowski sum are prone to challenges that arise in the context of 3D geometric algorithms: 1) not robust to numerical error, 2) susceptible to handling degeneracies (i.e., cannot reliably handle polygon soups or meshes with holes). There is some recent work~\cite{Lien:2008:CMS,Lien:2007:ACD,Lien:2009:ASM} on computing the approximate Minkowski sum efficiently and reliably, but these methods are also prone to robustness issues and can have high complexity in terms of dealing with complex objects. There exists some work considering $\Cobs$ computation other than Minkowski sum. For example, Varadhan et al. compute the $\Cobs$ for 2D objects with rotation and translation, i.e., when $\Cspace = \SEsqr$~\cite{Varadhan:2006:TPA}; Zhang et al. compute an approximation to 4-D $\Cspace$ using cell decomposition~\cite{Zhang:2007:IROS}.

Topology-based methods capture the connectivity of the configuration space. Most previous approaches attempt to capture the connectivity of $\Cfree$ using sampling techniques~\cite{Kavraki96,Kuffner00}. The basic idea is first to generate random samples (called the milestones) in $\Cfree$ and then organize these samples using a graph structure or a forest of tree structures (Figure~\ref{fig:1:topologycspace}). As the topology of $\Cfree$ can be rather complex, and
may consist of multiple components or small, narrow passages, it is hard to capture the full connectivity of $\Cfree$ using random sampling. There is extensive work on various techniques to improve the connectivity computation by using different sampling strategies~\cite{Amato:1998:OOP,Boor:1999:ICRA,Hsu:1998:FNP,Rodriguez:2006,Zhang:2008:ICRA,Zheng:2005}. Some recent work attempts to capture the topology of both $\Cfree$ and $\Cobs$~\cite{Jory:2011:IROS}. Topology-based methods can compute an approximate $\Cspace$ representation much faster than geometry-based methods. However, they suffer from the narrow passage challenges and can be slow for high-DOF robots.


\begin{figure}[htb]
  \centering
  \subfloat[Graph representation]{\includegraphics[width=0.49\linewidth]{figs/1/topology1.pdf}}
  \subfloat[Tree representation]{\includegraphics[width=0.49\linewidth]{figs/1/topology2.pdf}}
  \caption[Topology-based methods for configuration space computation]{Topology-based methods for configuration space computation. (a) Capture $\Cfree$ using a graph structure. (b) Capture $\Cfree$ using a forest of tree structures. The two figures are modified from Jean-Claude Latombe's lecture slides.}\label{fig:1:topologycspace}
\end{figure}




\section{Optimization in Configuration Space}
\label{sec:1:optimization}
Once an exact or approximate representation for the configuration space is computed, we next need to perform computation/optimization in $\Cspace$ representation. For example, the goal of motion planning is to compute a trajectory in $\Cspace$, as shown in Figure~\ref{fig:1:planning}. The trajectory should satisfy different constraints: 1) it should be completely inside $\Cfree$; 2) it should be feasible, e.g., for humanoid robots, the robot should not fall down onto the ground when following the trajectory, etc. Moreover, 
it is preferable for the trajectory to be optimal under some metric: 1) it should be shortest; or 2) it should be executed with minimum time; or 3) it should have the maximum margin to the obstacles, etc. As a result, motion planning can be formalized as a constrained optimization in $\Cspace$. Similar formulation can be applied to different applications, such as penetration depth computation~\cite{Zhang:2007:GPD,Zhang:2007:AFP,Zhang:2008:ICRA,Je:2012:PRP}.


\begin{figure}[htb]
  \centering
  \includegraphics[width=\linewidth]{figs/1/planning-crop.pdf}
  \caption[Motion planning in workspace and in configuration space]{Motion planning in workspace and in configuration space. Left figure shows the obstacles (with different colors) and the 2-linked robot in workspace (both the initial and goal settings). Right figure shows the configuration space corresponding to the workspace in the left figure, where different colors describe the correspondence relationship between obstacles in workspace and obstacles in configuration space. The curve is the trajectory connecting the initial and goal configurations and is the result of motion planning algorithm. The figure is modified from~\cite{cspaceJapplet}. \label{fig:1:planning}}
\end{figure}


Optimization in $\Cspace$ is usually computationally expensive, especially for high-dimensional $\Cspace$ with complicated structure and topology. Let's take motion planning as an example. Theoretically, motion planning using the exact representation of $\Cspace$ has high computational complexity. Some planning algorithms are considered as `complete', i.e., for any planning problem instance, the algorithm will either find a solution or will correctly report that no solutions exists. Complete planning algorithms have been proved to be PSPACE-hard~\cite{Reif:1979:CMP} and PSPACE-complete~\cite{Canny:1988:AGC} and kinodynamic motion planning (i.e., motion planning with simple kinematic/dynamic constraints) has been shown to be NEXPTIME-hard~\cite{Canny:1988:CKP}. For motion planning with exact representation of $\Cspace$ with general differential constraints, even its decidability is still unknown~\cite{Cheng:2007:DMP}. When the approximate representation of $\Cspace$ is used (e.g., using a graph or forest to represent the connectivity of $\Cfree$), there exists extensive work about approximate motion planning algorithms, which provide guarantees of probabilistic completeness~\cite{Kavraki96,Kuffner00} and/or asymptotic optimality~\cite{Sertac:IJRR:2011}. The complexity of these approximate motion planning algorithms is usually bounded by $\mathcal O(n\lg n)$ where $n$ is the number of configuration samples used in the approximate representation of $\Cspace$. As $n$ can be very large when $\Cfree$ has narrow passages and/or with high dimensionality~\cite{Hsu:2006:ijrr}, the performance of these approximate algorithms are still far from real-time.


Various planning methods have been proposed in the past decades, including optimization-based planning algorithms such as CHOMP~\cite{Ratliff:2009} and search-based algorithms such as Anytime A*~\cite{Likhachev05anytimedynamic}. For motion planning of high-DOF (degrees-of-freedom) robots, most of the practical methods are based on randomized algorithms, including Probabilistic Roadmap (PRM)~\cite{Kavraki96} and Rapidly Exploring Random Tree (RRT)~\cite{Kuffner00}.


\section{Uncertainty Modeling in Configuration Space}
\label{sec:1:uncertainty}
Most prior techniques assumed that an exact geometric representation is known for the robot and obstacles in the environment. This is reasonable in applications such as computer graphics, CAD, and simulation, where the geometric representation of synthetic objects is available. As a result, there is no ambiguity about the collision status of any configuration $\mathbf q \in \Cspace$: either $\q \in \Cfree$ and being collision-free or $\q \in \Cobs$ and being in-collision.

Unfortunately, the exact geometric representation assumption may not hold when we are dealing with real-world robots that interact with the physical environment. In the real world, sensors, be
it laser-range finders or imaging devices, do not provide exact geometric representation, but rather noisy point clouds. In these cases, the noise arises from device noise, limited field-of-view, sensor refresh latency, synchronization error or even occlusions. For noisy geometric representations, we cannot deterministically compute the collision status of a given configuration $\q$. Instead, $\q$ may lie in $\Cfree$ with probability $p$ or lie in $\Cobs$ with probability $1-p$, where $0 \leq p \leq 1$. How to compute $p$ of any configuration $\q \in \Cspace$ for any given sensor data is an open problem not studied in previous work.

The problem of modeling uncertainty in configuration space has many applications. For example, it can be combined with motion planning algorithms to compute a trajectory with the minimum probability to collide with the obstacles and therefore improve the safety of robot navigation. Moreover, it can be used to extend many classical computational geometry algorithms to handle noisy sensor data, such as Minkowski sums~\cite{Varadhan:2006:TPA} and offsets~\cite{Choi:1997:CAD}.

\section{Thesis Statement}

Our thesis is as follows:

\textit{High-dimensional configuration spaces can be efficiently approximated using machine learning and geometric algorithms, and used for optimization queries related to motion planning and proximity computations on exact and noisy datasets.}

\section{Main Results}
In support of our thesis, we present new techniques about configuration space construction, optimization computation in configuration space, and modeling uncertainty in configuration space. First, we demonstrate how to convert the configuration space construction problem into a machine learning problem and use active learning to compute an approximate configuration space efficiently and robustly. We also discuss how to use of instance-based learning techniques to incrementally compute an approximate configuration space, which is used to enable robots learn from their past experiences about task execution. Second, we provide methods to accelerate the optimization computations in the configuration space using parallel GPU-based algorithms, which can result in real-time planning computation in many challenging environments. Finally, we propose two different methods to model the uncertainty in the configuration space caused by noisy geometries, which are then combined with active sensing techniques to enable robots work reliably in environment with uncertainty.

\subsection{Efficient $\Cspace$ Construction}
In this part, we describe two different methods to compute approximate representation of the configuration space. The first is a geometry-based method and the second is a topology-based method.

First, we present a novel technique to efficiently approximate $\Ccont$ between two rigid objects using machine learning techniques. We first generate a set of samples in $\Cspace$ using collision detection techniques. We use non-linear SVM-based regression to construct an initial (coarse) approximation of $\Ccont$. Then we use active learning techniques to refine this approximation. We give error bounds on approximation to compute high-dimensional configuration
spaces and highlight the performance on many complex benchmarks. Additionally, based on the computed configuration space, we present an algorithm to efficiently approximate the penetration depth between two rigid objects, which is important in physically-based simulation.

Second, we present a novel approach to incrementally construct an approximate representation of $\Cspace$ from the samples generated during prior executions of the planning algorithm. Our formulation stores the results of prior
collision queries and local planning queries. This information is used to accelerate the performance of planners. We present fast and novel algorithms to perform $\knn$ ($k$-nearest neighbor) queries in high dimensional $\Cspace$ and derive tight bounds on their accuracy. Our approach is general, makes no assumptions about the sampling scheme, and can be used with various sample-based motion planners with only small changes to these planners. Additionally, we discuss how to use this method to enable the planner learn from its past query instances.

\subsection{Efficient Optimization in $\Cspace$}
In this part, we present techniques to accelerate optimization computation in $\Cspace$ using capabilities of many-core GPUs. This includes a GPU-based parallel planning algorithm called g-Planner. In g-Planner, GPU is used to improve the performance for two main bottlenecks of sample-based planning algorithms: collision detection and $k$-nearest neighbor search, which can take more than 95\% of the overall planning time. We present a new GPU-based parallel collision detection
algorithm, which is able to efficiently handle a large number (e.g., more than 100,000) of collision queries between objects of varying complexity and provides more than 60 times speed up compared to single-core CPU
algorithms. For $\knn$ search queries, we describe a new approximate algorithm for $\knn$ search based on Locality-Sensitive
Hashing (LSH), which is a GPU-friendly algorithm with sub-linear complexity and bounded error. The resulting
parallel GPU-based $\knn$ is at least 50 times faster than the optimized single-core CPU implementation.

\subsection{Uncertainty Modeling in $\Cspace$}
Our results on modeling configuration space for noisy geometric representations include two parts.

In the first part, we discuss a probabilistic collision detection algorithm between two objects represented as noisy point clouds. We convert the collision problem into a two-class classification problem and use extended SVM algorithms to solve it. To improve efficiency, a divide-and-conquer method is used to eliminate some unnecessary computations. Instead of only a binary result (collision or not) provided by traditional collision algorithms, our method computes a collision probability, which is useful for robotics applications that require detailed measure of collision status, such as grasping.

Point cloud representation of noisy environment has some problems. First, the point cloud provided by many
sensors may be too dense for real-time processing. Second, point clouds can only model occupied
regions in the environment and cannot model unknown regions or the open regions, which may result in serious
problems for motion planning. As a result, in the second part of this work, we present efficient collision detection and
distance computation algorithms for environment data represented as an octree, which can model occupied,
unknown, and free regions. Our algorithm can provide a collision probability or a distance bound. Moreover,
this method also takes into consideration the fact that the sensor data usually arrives at a high rate (i.e., point cloud streams), and it is
difficult to track it precisely. This algorithm is used to guide Willow Garage's PR2 robot to operate safely in
not-well mapped regions with dynamic obstacles.

\section{Organization}
The remainder of this dissertation is organized as follows.

 \begin{description}
 \item[Chapter~\ref{chp:APD}] presents a geometry-based configuration space approximation with active learning technique.
 \item[Chapter~\ref{chp:IBL}] describes a topology-based configuration space representation with instance-based learning technique.
 \item[Chapter~\ref{chp:GPlanner}] presents a GPU-based motion planning framework for probabilistic roadmaps.
 \item[Chapter~\ref{chp:GCollide}] describes the GPU-based collision detection used in GPU-based motion planning.
 \item[Chapter~\ref{chp:GLSH}] presents the GPU-based $k$-nearest neighbor used in GPU-based motion planning.
 \item[Chapter~\ref{chp:PCollide}] presents how to model the uncertainty for a configuration when the geometry is point cloud sensor data.
 \item[Chapter~\ref{chp:PCollide2}] improves Chapter~\ref{chp:PCollide}'s performance on point cloud stream data.
 \item[Chapter~\ref{chp:Conclusion}] presents conclusions and future work.
 \end{description}


